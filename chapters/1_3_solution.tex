%! Author = wxw85
%! Date = 01/08/2022

\section{Solution}\label{sec:solution}
%**************************************************************
To solve the problem of visual odometry, we tried different approaches to feed the data into the model, and to construct the model itself.
We tried following approaches to feed the data:
\begin{itemize}
    \item Feeding the sequence into the model directly and presenting the pose as \emph{euler angles}.
    \item Feeding the sequence into the model directly and presenting the pose as \emph{rotation matrix} and \emph{translation vector}.
    \item Feeding the sequence into the model where the first frame is the origin of the reference frame and presenting the pose as \emph{euler angles}.
    \item Feeding the sequence into the model where the first frame is the origin of the reference frame and presenting the pose as \emph{rotation matrix} and \emph{translation vector}.
\end{itemize}

We used these input strategies to feed the sequence, we tried different variants of models:
\begin{itemize}
    \item Using the different version of ResNet (producing \gls{embedding} of size 512 and 2048) model as feature extractor attached to the transformer with only encoder part.
    \item Using a \gls{mlp} for the images divided into patches to extract the features, and concatenating all the features as a single embedding then feed it into the only-encoder version of transformer.
    \item Using a MLP for the images divided into patches to extract the features, and concatenating all the features as a single embedding then feed it into the encoder-decoder version of transformer.
    \item Using the different version of ResNet model as feature extractor attached to the transformer with encoder and decoder.
    \item The same model as the previous but implemented in \gls{auto-regressive} mode.
\end{itemize}